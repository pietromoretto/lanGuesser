{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lanGuesser.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_-ESGicRrz6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf \n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krr-IGjBaZ6Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "467848a0-e5e5-40e3-c500-4fd81342eb74"
      },
      "source": [
        "# Download the dataset from GitHub repo\n",
        "!curl -O https://media.githubusercontent.com/media/pietromoretto/lanGuesser/master/dataset.csv"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  109M  100  109M    0     0  40.0M      0  0:00:02  0:00:02 --:--:-- 39.9M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ttzjmpDUc_Y",
        "colab_type": "code",
        "outputId": "338fc96b-34f6-49e3-b9f9-bed4e5de32ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset.csv  keras_saved_model.h5  __pycache__\ttokenizer_state.pkl\n",
            "gdrive\t     predictor.py\t   sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM04PZZJK-Fq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "convert = {\n",
        "    \".c\": \"C\",\n",
        "    \".java\": \"JAVA\",\n",
        "    \".py\": \"PYTHON\",\n",
        "    \".rb\": \"RUBY\",\n",
        "    \".html\": \"HTML\",\n",
        "    \".css\": \"CSS\",\n",
        "    \".php\": \"PHP\",\n",
        "    \".sql\": \"SQL\",\n",
        "    \".cs\": \"C#\",\n",
        "    \".js\": \"JAVASCRIPT\",\n",
        "    \".go\": \"GO\",\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9neqv5qR08s",
        "colab_type": "code",
        "outputId": "de1ffcbb-4406-4bf2-e6e5-6c070761b0aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "# Create the dataframe\n",
        "\n",
        "data = pd.read_csv(\"dataset.csv\")\n",
        "\n",
        "data = shuffle(data, random_state=22)\n",
        "data = data.dropna()\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7967</th>\n",
              "      <td>// Copyright 2014 The go-ethereum Authors\\n// ...</td>\n",
              "      <td>GO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7845</th>\n",
              "      <td>// Copyright 2013, Google Inc. All rights rese...</td>\n",
              "      <td>GO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2812</th>\n",
              "      <td># Copyright (c) 2003-2014 CORE Security Techno...</td>\n",
              "      <td>PYTHON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11944</th>\n",
              "      <td>/*\\n * Clover - 4chan browser https://github.c...</td>\n",
              "      <td>JAVA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15611</th>\n",
              "      <td>$LOAD_PATH.unshift File.expand_path('../../lib...</td>\n",
              "      <td>RUBY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 content language\n",
              "7967   // Copyright 2014 The go-ethereum Authors\\n// ...       GO\n",
              "7845   // Copyright 2013, Google Inc. All rights rese...       GO\n",
              "2812   # Copyright (c) 2003-2014 CORE Security Techno...   PYTHON\n",
              "11944  /*\\n * Clover - 4chan browser https://github.c...     JAVA\n",
              "15611  $LOAD_PATH.unshift File.expand_path('../../lib...     RUBY"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "simcY9jXEXri",
        "colab_type": "code",
        "outputId": "42a2aa20-4f23-4f69-dda3-76e61b8ecca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "# Print how many languages are in the dataset\n",
        "\n",
        "for k, v in convert.items():\n",
        "    cust = data[\"language\"].apply(lambda lan: lan == v)\n",
        "    print(v, len(cust[cust == True]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C 427\n",
            "JAVA 1931\n",
            "PYTHON 1630\n",
            "RUBY 3935\n",
            "HTML 574\n",
            "CSS 715\n",
            "PHP 2033\n",
            "SQL 1229\n",
            "C# 1958\n",
            "JAVASCRIPT 435\n",
            "GO 1487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdeA0FkUANTD",
        "colab_type": "code",
        "outputId": "a88ba140-b033-4ba8-ebed-1b2dc3cdc749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>16354</td>\n",
              "      <td>16354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>16354</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>UPDATE `spell_proc_event` SET `procFlags`=0x14...</td>\n",
              "      <td>RUBY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>3935</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  content language\n",
              "count                                               16354    16354\n",
              "unique                                              16354       11\n",
              "top     UPDATE `spell_proc_event` SET `procFlags`=0x14...     RUBY\n",
              "freq                                                    1     3935"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3GpJSV5TysR",
        "colab_type": "code",
        "outputId": "10b256be-617d-4433-9279-444059ffeab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# One Hot Encoding on programming languages (labels)\n",
        "\n",
        "encoder = LabelBinarizer()\n",
        "lang_encoded = encoder.fit_transform(data[\"language\"].values)\n",
        "num_lang = len(lang_encoded[0])\n",
        "\n",
        "print(data['language'].values[0])\n",
        "print(encoder.classes_)\n",
        "print(lang_encoded[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GO\n",
            "['C' 'C#' 'CSS' 'GO' 'HTML' 'JAVA' 'JAVASCRIPT' 'PHP' 'PYTHON' 'RUBY'\n",
            " 'SQL']\n",
            "[0 0 0 1 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0Mx4FguUbAw",
        "colab_type": "code",
        "outputId": "1d31f946-c261-4912-dcd9-d735eff5cd8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Split data into train and test sets (80 / 20)\n",
        "\n",
        "train_size = int(len(data) * .8)\n",
        "test_size = (len(data) - train_size)\n",
        "\n",
        "print(f\"Train size: {train_size}\")\n",
        "print (f\"Test size: {test_size}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 13083\n",
            "Test size: 3271\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRbdQeGdUjet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split labels into train and test sets\n",
        "\n",
        "train_lang = lang_encoded[:train_size]\n",
        "test_lang = lang_encoded[train_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7pV7edctRrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize the features\n",
        "\n",
        "from tensorflow.keras.preprocessing import text\n",
        "\n",
        "VOCAB_SIZE=400 \n",
        "\n",
        "train_content = data['content'].values[:train_size]\n",
        "test_content = data['content'].values[train_size:]\n",
        "\n",
        "tokenizer = text.Tokenizer(num_words=VOCAB_SIZE)\n",
        "tokenizer.fit_on_texts(train_content)\n",
        "\n",
        "body_train = tokenizer.texts_to_matrix(train_content)\n",
        "body_test = tokenizer.texts_to_matrix(test_content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vYhQytlthcI",
        "colab_type": "code",
        "outputId": "e85fd863-fd81-4e5d-a708-81e004638a61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        }
      },
      "source": [
        "# Preview the first input from our training data\n",
        "\n",
        "print(len(body_train[0]))\n",
        "print(body_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400\n",
            "[0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSjf1Ipz4-6h",
        "colab_type": "code",
        "outputId": "442526be-90d3-4037-ebe6-7cee94738799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "# Create the model\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(50, input_shape=(VOCAB_SIZE,), activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(25, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(num_lang, activation='softmax'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 50)                20050     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 25)                1275      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 11)                286       \n",
            "=================================================================\n",
            "Total params: 21,611\n",
            "Trainable params: 21,611\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvkOsqNt5no3",
        "colab_type": "code",
        "outputId": "befa54bc-8d00-4807-d5e5-fec4e6725d53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "source": [
        "# Train and evaluate the model\n",
        "\n",
        "model.fit(body_train, train_lang, epochs=10, batch_size=128, validation_split=0.1)\n",
        "\n",
        "print('Eval loss/accuracy: {}\".format(model.evaluate(body_test, test_lang, batch_size=128)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11774 samples, validate on 1309 samples\n",
            "Epoch 1/10\n",
            "11774/11774 [==============================] - 0s 23us/sample - loss: 3.9294e-04 - acc: 0.9999 - val_loss: 0.0518 - val_acc: 0.9922\n",
            "Epoch 2/10\n",
            "11774/11774 [==============================] - 0s 21us/sample - loss: 3.8223e-04 - acc: 0.9999 - val_loss: 0.0521 - val_acc: 0.9924\n",
            "Epoch 3/10\n",
            "11774/11774 [==============================] - 0s 21us/sample - loss: 3.7697e-04 - acc: 0.9999 - val_loss: 0.0524 - val_acc: 0.9923\n",
            "Epoch 4/10\n",
            "11774/11774 [==============================] - 0s 21us/sample - loss: 3.7303e-04 - acc: 0.9999 - val_loss: 0.0529 - val_acc: 0.9919\n",
            "Epoch 5/10\n",
            "11774/11774 [==============================] - 0s 23us/sample - loss: 3.6909e-04 - acc: 0.9999 - val_loss: 0.0529 - val_acc: 0.9922\n",
            "Epoch 6/10\n",
            "11774/11774 [==============================] - 0s 23us/sample - loss: 3.6876e-04 - acc: 0.9999 - val_loss: 0.0531 - val_acc: 0.9923\n",
            "Epoch 7/10\n",
            "11774/11774 [==============================] - 0s 22us/sample - loss: 3.6799e-04 - acc: 0.9999 - val_loss: 0.0535 - val_acc: 0.9922\n",
            "Epoch 8/10\n",
            "11774/11774 [==============================] - 0s 23us/sample - loss: 3.6038e-04 - acc: 0.9999 - val_loss: 0.0539 - val_acc: 0.9922\n",
            "Epoch 9/10\n",
            "11774/11774 [==============================] - 0s 21us/sample - loss: 3.6462e-04 - acc: 0.9999 - val_loss: 0.0541 - val_acc: 0.9920\n",
            "Epoch 10/10\n",
            "11774/11774 [==============================] - 0s 21us/sample - loss: 3.5786e-04 - acc: 0.9999 - val_loss: 0.0540 - val_acc: 0.9922\n",
            "3271/3271 [==============================] - 0s 13us/sample - loss: 0.0340 - acc: 0.9948\n",
            "Eval loss/accuracy: [0.033974358766419153, 0.9947752]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMtAn5vS6RTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Export the model to a file\n",
        "\n",
        "model.save('keras_saved_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4o9yJ-l8HF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the processor state of the tokenizer\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open('./tokenizer_state.pkl', 'wb') as f:\n",
        "  pickle.dump(tokenizer, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqH3QKHd8aPI",
        "colab_type": "code",
        "outputId": "c32c3d11-4c79-4d83-d561-17530377aeb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%%writefile predictor.py\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Predictor:\n",
        "  def __init__(self, model, processor):\n",
        "    self._model = model\n",
        "    self._processor = processor\n",
        "  \n",
        "  def predict(self, instances, **kwargs):\n",
        "    preprocessed_data = self._processor.texts_to_matrix(instances)\n",
        "    predictions = self._model.predict(preprocessed_data)\n",
        "    return predictions.tolist()\n",
        "\n",
        "  @classmethod\n",
        "  def from_path(cls, model_dir):\n",
        "    import tensorflow.keras as keras\n",
        "    model = keras.models.load_model(\n",
        "      os.path.join(model_dir,'keras_saved_model.h5'))\n",
        "    with open(os.path.join(model_dir, 'tokenizer_state.pkl'), 'rb') as f:\n",
        "      processor = pickle.load(f)\n",
        "\n",
        "    return cls(model, processor)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting predictor.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85GLPEZe6oS2",
        "colab_type": "code",
        "outputId": "75e1ae0d-806b-4abf-e67b-5fef3a1c6da3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "# Test model on custom data\n",
        "\n",
        "from predictor import Predictor\n",
        "\n",
        "\n",
        "test = [\n",
        "    \"\"\"public class OracleJdbcTest\n",
        "{\n",
        "\tString driverClass = \"oracle.jdbc.driver.OracleDriver\";\n",
        "\n",
        "\tConnection con;\n",
        "\t\n",
        "\tpublic void init(FileInputStream fs) throws ClassNotFoundException, SQLException, FileNotFoundException, IOException\n",
        "\t{\n",
        "\t\tProperties props = new Properties();\n",
        "\t\tprops.load(fs);\n",
        "\t\tString url = props.getProperty(\"db.url\");\n",
        "\t\tString userName = props.getProperty(\"db.user\");\n",
        "\t\tString password = props.getProperty(\"db.password\");\n",
        "\t\tClass.forName(driverClass);\n",
        "\n",
        "\t\tcon=DriverManager.getConnection(url, userName, password);\n",
        "\t}\n",
        "\t\n",
        "\tpublic void fetch() throws SQLException, IOException\n",
        "\t{\n",
        "\t\tPreparedStatement ps = con.prepareStatement(\"select SYSDATE from dual\");\n",
        "\t\tResultSet rs = ps.executeQuery();\n",
        "\t\t\n",
        "\t\twhile (rs.next())\n",
        "\t\t{\n",
        "\t\t\t// do the thing you do\n",
        "\t\t}\n",
        "\t\trs.close();\n",
        "\t\tps.close();\n",
        "\t}\n",
        "\n",
        "\tpublic static void main(String[] args) \n",
        "\t{\n",
        "\t\tOracleJdbcTest test = new OracleJdbcTest();\n",
        "\t\ttest.init();\n",
        "\t\ttest.fetch();\n",
        "\t}\n",
        "}\"\"\",\n",
        "    \"\"\"java.util.Date utilDate = new java.util.Date();\n",
        "java.sql.Date sqlDate = new java.sql.Date(utilDate.getTime());\"\"\",\n",
        "    \"\"\"import socket\n",
        "import subprocess\n",
        "import sys\n",
        "from datetime import datetime\n",
        "\n",
        "# Clear the screen\n",
        "subprocess.call('clear', shell=True)\n",
        "\n",
        "# Ask for input\n",
        "remoteServer    = raw_input(\"Enter a remote host to scan: \")\n",
        "remoteServerIP  = socket.gethostbyname(remoteServer)\n",
        "\n",
        "# Print a nice banner with information on which host we are about to scan\n",
        "print \"-\" * 60\n",
        "print \"Please wait, scanning remote host\", remoteServerIP\n",
        "print \"-\" * 60\n",
        "\n",
        "# Check what time the scan started\n",
        "t1 = datetime.now()\n",
        "\n",
        "# Using the range function to specify ports (here it will scans all ports between 1 and 1024)\n",
        "\n",
        "# We also put in some error handling for catching errors\n",
        "\n",
        "try:\n",
        "    for port in range(1,1025):  \n",
        "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "        result = sock.connect_ex((remoteServerIP, port))\n",
        "        if result == 0:\n",
        "            print \"Port {}: \t Open\".format(port)\n",
        "        sock.close()\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print \"You pressed Ctrl+C\"\n",
        "    sys.exit()\n",
        "\n",
        "except socket.gaierror:\n",
        "    print 'Hostname could not be resolved. Exiting'\n",
        "    sys.exit()\n",
        "\n",
        "except socket.error:\n",
        "    print \"Couldn't connect to server\"\n",
        "    sys.exit()\n",
        "\n",
        "# Checking the time again\n",
        "t2 = datetime.now()\n",
        "\n",
        "# Calculates the difference of time, to see how long it took to run the script\n",
        "total =  t2 - t1\n",
        "\n",
        "# Printing the information to screen\n",
        "print 'Scanning Completed in: ', total\"\"\",\n",
        "    \"\"\"def a():\n",
        "                print(12)\"\"\",\n",
        "]\n",
        "\n",
        "\n",
        "predictor = Predictor.from_path(\".\")\n",
        "results = predictor.predict(test)\n",
        "\n",
        "for result in results:\n",
        "  print(\"Predicted labels:\")\n",
        "  max_pred = -10000\n",
        "  max_i = -1\n",
        "  for i, pred in enumerate(result):\n",
        "    if pred > max_pred:\n",
        "      max_i = i\n",
        "      max_pred = pred\n",
        "    \n",
        "    \n",
        "  print(encoder.classes_[max_i], max_pred)\n",
        "  print()\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted labels:\n",
            "JAVA 0.9799880981445312\n",
            "\n",
            "Predicted labels:\n",
            "JAVA 0.9334894418716431\n",
            "\n",
            "Predicted labels:\n",
            "PYTHON 1.0\n",
            "\n",
            "Predicted labels:\n",
            "PYTHON 0.9999996423721313\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}